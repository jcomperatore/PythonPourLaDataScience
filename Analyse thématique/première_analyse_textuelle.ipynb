{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\pourt\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\pourt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\pourt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\pourt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pourt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pourt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectoriasation des textes du corpus à l'aide d'une approche \"bag of words\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorisation_bag_of_words(corpus):\n",
    "    \"\"\"\n",
    "    Vectorise un corpus de texte avec l'approche Bag of Words.\n",
    "\n",
    "    Args:\n",
    "    - corpus (list): Une liste de chaînes de texte.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (Matrice BoW, Liste des mots)\n",
    "    \"\"\"\n",
    "    # Initialiser le CountVectorizer\n",
    "    vectoriseur = CountVectorizer()\n",
    "\n",
    "    # Appliquer le CountVectorizer sur le corpus\n",
    "    matrice_bow = vectoriseur.fit_transform(corpus)\n",
    "\n",
    "    # Liste des mots (caractéristiques)\n",
    "    mots = vectoriseur.get_feature_names_out()\n",
    "\n",
    "    return matrice_bow, mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regrouper les textes d'un corpus en cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "1308\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_questions = pd.read_csv('C:\\\\Users\\\\pourt\\\\PythonPourLaDataScience\\\\Datascrapping\\\\data.csv', encoding='latin-1', sep='|')\n",
    "\n",
    "liste=[]\n",
    "for i in range(len(df_questions['question'])):\n",
    "    x=type(df_questions['question'][i])\n",
    "    if x!=str:\n",
    "        liste.append((x,i))\n",
    "print(liste)\n",
    "\n",
    "print(len(df_questions['question']))\n",
    "\n",
    "df_questions=df_questions.drop(159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_bow, mots = vectorisation_bag_of_words(df_questions['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3546)\t1\n",
      "  (0, 11330)\t1\n",
      "  (0, 9495)\t1\n",
      "  (0, 10044)\t4\n",
      "  (0, 10884)\t1\n",
      "  (0, 5060)\t14\n",
      "  (0, 1282)\t1\n",
      "  (0, 6941)\t10\n",
      "  (0, 9940)\t10\n",
      "  (0, 15973)\t1\n",
      "  (0, 1403)\t1\n",
      "  (0, 16295)\t3\n",
      "  (0, 16079)\t1\n",
      "  (0, 12189)\t1\n",
      "  (0, 5136)\t9\n",
      "  (0, 12265)\t7\n",
      "  (0, 3918)\t1\n",
      "  (0, 1829)\t1\n",
      "  (0, 3500)\t4\n",
      "  (0, 2653)\t2\n",
      "  (0, 1326)\t2\n",
      "  (0, 13786)\t4\n",
      "  (0, 10069)\t14\n",
      "  (0, 5415)\t2\n",
      "  (0, 10913)\t1\n",
      "  :\t:\n",
      "  (1306, 14602)\t2\n",
      "  (1306, 4247)\t1\n",
      "  (1306, 13616)\t1\n",
      "  (1306, 4845)\t1\n",
      "  (1306, 14084)\t3\n",
      "  (1306, 7060)\t1\n",
      "  (1306, 7493)\t1\n",
      "  (1306, 13748)\t1\n",
      "  (1306, 10008)\t1\n",
      "  (1306, 8047)\t2\n",
      "  (1306, 15381)\t1\n",
      "  (1306, 8248)\t1\n",
      "  (1306, 6351)\t1\n",
      "  (1306, 7605)\t5\n",
      "  (1306, 4975)\t2\n",
      "  (1306, 7042)\t1\n",
      "  (1306, 13575)\t1\n",
      "  (1306, 5572)\t1\n",
      "  (1306, 9939)\t1\n",
      "  (1306, 659)\t1\n",
      "  (1306, 9577)\t1\n",
      "  (1306, 10812)\t2\n",
      "  (1306, 7909)\t1\n",
      "  (1306, 10007)\t1\n",
      "  (1306, 7050)\t1\n"
     ]
    }
   ],
   "source": [
    "print(matrice_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def clustering_kmeans_lignes(matrice_sparse, nombre_clusters):\n",
    "    \"\"\"\n",
    "    Effectue le clustering des lignes d'une matrice sparse avec la méthode des k-means.\n",
    "\n",
    "    Args:\n",
    "    - matrice_sparse (scipy.sparse.csr_matrix): Matrice sparse.\n",
    "    - nombre_clusters (int): Nombre de clusters à former.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Tableau des étiquettes de cluster pour chaque ligne.\n",
    "    \"\"\"\n",
    "    if not isinstance(matrice_sparse, csr_matrix):\n",
    "        raise ValueError(\"La matrice doit être au format csr_matrix.\")\n",
    "\n",
    "\n",
    "    # Appliquer la méthode des k-means\n",
    "    kmeans = KMeans(n_clusters=nombre_clusters, random_state=42)\n",
    "    etiquettes_clusters = kmeans.fit_predict(matrice_sparse)\n",
    "\n",
    "    return etiquettes_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse en composante principale et représentation graphique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration et test de nos fonction sur un corpus très simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Ceci est le premier document.\", \"Ceci est le deuxième document.\", \"Et voici le troisième document.\", \"Nous sommes allés en soirée Lundi.\",\"Nous sommes allés en soirée Mardi.\",\"Nous sommes allés en soirée Mercredi.\"]\n",
    "#On crée un corpus de texte très simple avec 6 texte qu'on classe intuitivement en deux groupes très homogènes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On obtient la matrice suivante :\n",
      "[[0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0]\n",
      " [1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0]\n",
      " [1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0]]\n",
      "['allés' 'ceci' 'deuxième' 'document' 'en' 'est' 'et' 'le' 'lundi' 'mardi'\n",
      " 'mercredi' 'nous' 'premier' 'soirée' 'sommes' 'troisième' 'voici']\n"
     ]
    }
   ],
   "source": [
    "matrice_bow, mots = vectorisation_bag_of_words(corpus)\n",
    "print(\"On obtient la matrice suivante :\")\n",
    "print(matrice_bow.toarray())\n",
    "print(mots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Étiquettes des clusters pour les différents texte du corpus : [0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "etiquettes_clusters_lignes = clustering_kmeans_lignes(matrice_bow, 2)\n",
    "print(\"Étiquettes des clusters pour les différents texte du corpus :\", etiquettes_clusters_lignes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
